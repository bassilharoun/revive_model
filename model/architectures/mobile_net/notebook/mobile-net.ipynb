{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 19:32:13.922453: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-07 19:32:13.964053: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-07 19:32:14.761092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras\n",
    "# !pip install tensorflow\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input, LSTM, concatenate, ConvLSTM2D, Conv2D, Lambda, Reshape\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.nn import softmax, leaky_relu\n",
    "from tensorflow import expand_dims, einsum\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "index_Spine_Base = 0\n",
    "index_Spine_Mid = 4\n",
    "index_Neck = 8\n",
    "index_Head = 12  # no orientation\n",
    "index_Shoulder_Left = 16\n",
    "index_Elbow_Left = 20\n",
    "index_Wrist_Left = 24\n",
    "index_Hand_Left = 28\n",
    "index_Shoulder_Right = 32\n",
    "index_Elbow_Right = 36\n",
    "index_Wrist_Right = 40\n",
    "index_Hand_Right = 44\n",
    "index_Hip_Left = 48\n",
    "index_Knee_Left = 52\n",
    "index_Ankle_Left = 56\n",
    "index_Foot_Left = 60  # no orientation\n",
    "index_Hip_Right = 64\n",
    "index_Knee_Right = 68\n",
    "index_Ankle_Right = 72\n",
    "index_Foot_Right = 76  # no orientation\n",
    "index_Spine_Shoulder = 80\n",
    "index_Tip_Left = 84  # no orientation\n",
    "index_Thumb_Left = 88  # no orientation\n",
    "index_Tip_Right = 92  # no orientation\n",
    "index_Thumb_Right = 96  # no orientation\n",
    "\n",
    "\n",
    "class Data_Loader:\n",
    "    def __init__(self, dir):\n",
    "        self.num_repitation = 5\n",
    "        self.num_channel = 3\n",
    "        self.dir = dir\n",
    "        self.body_part = self.body_parts()\n",
    "        self.dataset = []\n",
    "        self.sequence_length = []\n",
    "        self.num_timestep = 100\n",
    "        self.new_label = []\n",
    "        self.train_x, self.train_y = self.import_dataset()\n",
    "        self.batch_size = self.train_y.shape[0]\n",
    "        self.num_joints = len(self.body_part)\n",
    "        self.sc1 = StandardScaler()\n",
    "        self.sc2 = StandardScaler()\n",
    "        self.scaled_x, self.scaled_y = self.preprocessing()\n",
    "\n",
    "    def body_parts(self):\n",
    "        body_parts = [\n",
    "            index_Spine_Base,\n",
    "            index_Spine_Mid,\n",
    "            index_Neck,\n",
    "            index_Head,\n",
    "            index_Shoulder_Left,\n",
    "            index_Elbow_Left,\n",
    "            index_Wrist_Left,\n",
    "            index_Hand_Left,\n",
    "            index_Shoulder_Right,\n",
    "            index_Elbow_Right,\n",
    "            index_Wrist_Right,\n",
    "            index_Hand_Right,\n",
    "            index_Hip_Left,\n",
    "            index_Knee_Left,\n",
    "            index_Ankle_Left,\n",
    "            index_Foot_Left,\n",
    "            index_Hip_Right,\n",
    "            index_Knee_Right,\n",
    "            index_Ankle_Right,\n",
    "            index_Ankle_Right,\n",
    "            index_Spine_Shoulder,\n",
    "            index_Tip_Left,\n",
    "            index_Thumb_Left,\n",
    "            index_Tip_Right,\n",
    "            index_Thumb_Right,\n",
    "        ]\n",
    "        return body_parts\n",
    "\n",
    "    def import_dataset(self):\n",
    "        train_x = (\n",
    "            pd.read_csv(\"./\" + self.dir + \"/Train_X.csv\", header=None).iloc[:, :].values\n",
    "        )\n",
    "        train_y = (\n",
    "            pd.read_csv(\"./\" + self.dir + \"/Train_Y.csv\", header=None).iloc[:, :].values\n",
    "        )\n",
    "        return train_x, train_y\n",
    "\n",
    "    def preprocessing(self):\n",
    "        X_train = np.zeros(\n",
    "            (self.train_x.shape[0], self.num_joints * self.num_channel)\n",
    "        ).astype(\"float32\")\n",
    "        for row in range(self.train_x.shape[0]):\n",
    "            counter = 0\n",
    "            for parts in self.body_part:\n",
    "                for i in range(self.num_channel):\n",
    "                    X_train[row, counter + i] = self.train_x[row, parts + i]\n",
    "                counter += self.num_channel\n",
    "\n",
    "        y_train = np.reshape(self.train_y, (-1, 1))\n",
    "        X_train = self.sc1.fit_transform(X_train)\n",
    "        y_train = self.sc2.fit_transform(y_train)\n",
    "\n",
    "        X_train_ = np.zeros(\n",
    "            (self.batch_size, self.num_timestep, self.num_joints, self.num_channel)\n",
    "        )\n",
    "\n",
    "        for batch in range(X_train_.shape[0]):\n",
    "            for timestep in range(X_train_.shape[1]):\n",
    "                for node in range(X_train_.shape[2]):\n",
    "                    for channel in range(X_train_.shape[3]):\n",
    "                        X_train_[batch, timestep, node, channel] = X_train[\n",
    "                            timestep + (batch * self.num_timestep),\n",
    "                            channel + (node * self.num_channel),\n",
    "                        ]\n",
    "\n",
    "        X_train = X_train_\n",
    "        return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self, num_node):\n",
    "        self.num_node = num_node\n",
    "        self.AD, self.AD2, self.bias_mat_1, self.bias_mat_2 = self.normalize_adjacency()\n",
    "        \n",
    "    def normalize_adjacency(self):\n",
    "        self_link = [(i, i) for i in range(self.num_node)]\n",
    "        neighbor_1base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21),\n",
    "                                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n",
    "                                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n",
    "                                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n",
    "                                      (22, 23), (23, 8), (24, 25), (25, 12)]\n",
    "        neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
    "        edge = self_link + neighbor_link    \n",
    "        A = np.zeros((self.num_node, self.num_node)) # adjacency matrix\n",
    "        for i, j in edge:\n",
    "            A[j, i] = 1\n",
    "            A[i, j] = 1\n",
    "        \n",
    "        A2 = np.zeros((self.num_node, self.num_node)) # second order adjacency matrix\n",
    "        for root in range(A.shape[1]):\n",
    "            for neighbour in range(A.shape[0]):\n",
    "                if A[root, neighbour] == 1:\n",
    "                    for neighbour_of_neigbour in range(A.shape[0]):\n",
    "                        if A[neighbour, neighbour_of_neigbour] == 1:\n",
    "                            A2[root,neighbour_of_neigbour] = 1                 \n",
    "        #AD = self.normalize(A)\n",
    "        #AD2 = self.normalize(A2)\n",
    "        bias_mat_1 = np.zeros(A.shape)\n",
    "        bias_mat_2 = np.zeros(A2.shape)\n",
    "        bias_mat_1 = np.where(A!=0, bias_mat_1, -1e9)\n",
    "        bias_mat_2 = np.where(A2!=0, A2, -1e9)\n",
    "        AD = A.astype('float32')\n",
    "        AD2 = A2.astype('float32')\n",
    "        bias_mat_1 = bias_mat_1.astype('float32')\n",
    "        bias_mat_2 = bias_mat_2.astype('float32')\n",
    "        AD = tf.convert_to_tensor(AD)\n",
    "        AD2= tf.convert_to_tensor(AD2)\n",
    "        bias_mat_1 = tf.convert_to_tensor(bias_mat_1)\n",
    "        bias_mat_2 = tf.convert_to_tensor(bias_mat_2)\n",
    "        return AD, AD2, bias_mat_1, bias_mat_2\n",
    "        \n",
    "    def normalize(self, adjacency):\n",
    "        rowsum = np.array(adjacency.sum(1))\n",
    "        r_inv = np.power(rowsum, -1).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0\n",
    "        r_mat_inv = np.diag(r_inv)\n",
    "        normalize_adj = r_mat_inv.dot(adjacency)\n",
    "        normalize_adj = normalize_adj.astype('float32')\n",
    "        normalize_adj = tf.convert_to_tensor(normalize_adj)   \n",
    "        return normalize_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GCNLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        AD, x = inputs\n",
    "        return tf.einsum('vw,ntwc->ntvc', AD, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sgcn_Lstm(): # Adding mp2vkv2\n",
    "    def __init__(self, train_x, train_y, valid_x, valid_y, AD, AD2, lr=0.0001, epoach=200, batch_size=10):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.valid_x = valid_x\n",
    "        self.valid_y = valid_y\n",
    "        self.AD = AD\n",
    "        self.AD2 = AD2\n",
    "        self.lr = lr\n",
    "        self.epoach =epoach\n",
    "        self.batch_size = batch_size\n",
    "        self.num_joints = 25\n",
    "\n",
    "\n",
    "    def _conv_layer(self, Input, filters):\n",
    "        x = Conv2D(filters=filters, kernel_size=(1,1), strides=1, activation='relu')(Input)\n",
    "        x = Dropout(0.25)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _gcn_layer(self, AD, x):\n",
    "        # gcn = tf.keras.layers.Lambda(lambda x: tf.einsum('vw,ntwc->ntvc', x[0], x[1]))([AD, x])\n",
    "        gcn = GCNLayer()([AD, x])\n",
    "        return gcn\n",
    "\n",
    "    def sgcn(self, Input):\n",
    "        x = self._conv_layer(Input, 64)\n",
    "        gcn_1 = self._gcn_layer(self.AD, x)\n",
    "        y = self._conv_layer(Input, 64)\n",
    "        gcn_2 = self._gcn_layer(self.AD2, y)\n",
    "        concatenated_gcn_1_2 = concatenate([gcn_1, gcn_2], axis=-1)\n",
    "\n",
    "        x = self._conv_layer(concatenated_gcn_1_2, 128)\n",
    "        gcn_3 = self._gcn_layer(self.AD, x)\n",
    "        y = self._conv_layer(concatenated_gcn_1_2, 128)\n",
    "        gcn_4 = self._gcn_layer(self.AD2, y)\n",
    "        concatenated_gcn_3_4 = concatenate([gcn_3, gcn_4], axis=-1)\n",
    "\n",
    "        gcn = tf.keras.layers.Reshape(target_shape=(-1,concatenated_gcn_3_4.shape[2]*concatenated_gcn_3_4.shape[3]))(concatenated_gcn_3_4)\n",
    "\n",
    "        return gcn\n",
    "\n",
    "    def Lstm(self,x):\n",
    "        rec = LSTM(80, return_sequences=True)(x)\n",
    "        rec = Dropout(0.25)(rec)\n",
    "        rec1 = LSTM(40, return_sequences=True)(rec)\n",
    "        rec1 = Dropout(0.25)(rec1)\n",
    "        rec2 = LSTM(40, return_sequences=True)(rec1)\n",
    "        rec2 = Dropout(0.25)(rec2)\n",
    "        rec3 = LSTM(80)(rec2)\n",
    "        rec3 = Dropout(0.25)(rec3)\n",
    "        return Dense(1, activation = 'linear')(rec3)\n",
    "\n",
    "    def build(self):\n",
    "        seq_input = Input(shape=(None, self.train_x.shape[2], self.train_x.shape[3]), batch_size=None)\n",
    "        sgcn_layer = self.sgcn(seq_input)\n",
    "        lstm_sgcn_layer = self.Lstm(sgcn_layer)\n",
    "        self.model = Model(seq_input, lstm_sgcn_layer)\n",
    "        return self.model\n",
    "\n",
    "    def train(self):\n",
    "        t = dt.now()\n",
    "\n",
    "        model = self.build()\n",
    "        model.compile(loss=tf.keras.losses.Huber(delta=0.1), optimizer= Adam(learning_rate=self.lr))\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience = 25)\n",
    "        checkpoint = ModelCheckpoint(\"models/model_ex5.keras\", monitor='val_loss', save_best_only=True, mode='auto', save_freq='epoch')\n",
    "\n",
    "        history = self.model.fit(\n",
    "            self.train_x,\n",
    "            self.train_y,\n",
    "            validation_data = (self.valid_x,self.valid_y),\n",
    "            epochs=self.epoach,\n",
    "            batch_size=self.batch_size,\n",
    "            callbacks=[checkpoint, early_stopping]\n",
    "            )\n",
    "\n",
    "        print('Training time: %s' % (dt.now() - t))\n",
    "\n",
    "        self.model.save(\"models/my_model_trained_exercise.keras\")\n",
    "\n",
    "        return history\n",
    "\n",
    "    def load_wights(self, file_path):\n",
    "      self.model.load_wights(file_path)\n",
    "\n",
    "    def save(self, file_path=\"models/my_model_trained_exercise.keras\"):\n",
    "        self.model.save(file_path)\n",
    "\n",
    "    def prediction(self, data):\n",
    "        return self.model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from data_processing import Data_Loader\n",
    "# from graph import Graph\n",
    "# from GCN.sgcn_lstm import Sgcn_Lstm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "random_seed = 42  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances:  298\n",
      "Validation instances:  75\n"
     ]
    }
   ],
   "source": [
    "exercise = 'data/KIMORE/Kimore_ex5'\n",
    "learning_rate = 0.0001\n",
    "# epoch = 500\n",
    "epoch = 5\n",
    "batch_size = 10\n",
    "\n",
    "\"\"\"import the whole dataset\"\"\"\n",
    "data_loader = Data_Loader(exercise)  # folder name -> Train.csv, Test.csv\n",
    "\n",
    "\"\"\"import the graph data structure\"\"\"\n",
    "graph = Graph(len(data_loader.body_part))\n",
    "\n",
    "\"\"\"Split the data into training and validation sets while preserving the distribution\"\"\"\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(data_loader.scaled_x, data_loader.scaled_y, test_size=0.2, random_state = random_seed)\n",
    "\n",
    "print(\"Training instances: \", len(train_x))\n",
    "print(\"Validation instances: \", len(valid_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# algorithm = Sgcn_Lstm(train_x, train_y, graph.AD, graph.AD2, graph.bias_mat_1, graph.bias_mat_2, lr = args.lr, epoach=args.epoch, batch_size=args.batch_size)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m Sgcn_Lstm(train_x, train_y, valid_x, valid_y, graph\u001b[38;5;241m.\u001b[39mAD, graph\u001b[38;5;241m.\u001b[39mAD2, lr \u001b[38;5;241m=\u001b[39m learning_rate, epoach\u001b[38;5;241m=\u001b[39mepoch, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m history \u001b[38;5;241m=\u001b[39m algorithm\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mSgcn_Lstm.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     55\u001b[0m     seq_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 56\u001b[0m     sgcn_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     lstm_sgcn_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLstm(sgcn_layer)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m Model(seq_input, lstm_sgcn_layer)\n",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m, in \u001b[0;36mSgcn_Lstm.sgcn\u001b[0;34m(self, Input)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msgcn\u001b[39m(\u001b[38;5;28mself\u001b[39m, Input):\n\u001b[0;32m---> 27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     gcn_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcn_layer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAD, x)\n\u001b[1;32m     29\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_layer(Input, \u001b[38;5;241m64\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36mSgcn_Lstm._conv_layer\u001b[0;34m(self, Input, filters)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_conv_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m, Input, filters):\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.25\u001b[39m)(x)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:771\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;66;03m################\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# 4. Call build\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m##########################\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# 5. Infer training value\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# Training phase for `Layer.call` is set via (in order of priority):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m# across nested calls.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m call_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_call_context()\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:1279\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, call_spec)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_default(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild):\n\u001b[1;32m   1273\u001b[0m     shapes_dict \u001b[38;5;241m=\u001b[39m update_shapes_dict_for_target_fn(\n\u001b[1;32m   1274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild,\n\u001b[1;32m   1275\u001b[0m         shapes_dict\u001b[38;5;241m=\u001b[39mshapes_dict,\n\u001b[1;32m   1276\u001b[0m         call_spec\u001b[38;5;241m=\u001b[39mcall_spec,\n\u001b[1;32m   1277\u001b[0m         class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     )\n\u001b[0;32m-> 1279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;66;03m# Check input spec again (after build, since self.input_spec\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;66;03m# may have been updated\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_input_compatibility(call_spec\u001b[38;5;241m.\u001b[39mfirst_arg)\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:223\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m--> 223\u001b[0m         \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:195\u001b[0m, in \u001b[0;36mBaseConv.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# compute_output_shape contains some validation logic for the input\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# shape, and make sure the output shape has all positive dimensions.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_output_shape(input_shape)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    206\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    213\u001b[0m     )\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:511\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, name)\u001b[0m\n\u001b[1;32m    509\u001b[0m initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(initializer)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m--> 511\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m# Will be added to layer.losses\u001b[39;00m\n\u001b[1;32m    521\u001b[0m variable\u001b[38;5;241m.\u001b[39mregularizer \u001b[38;5;241m=\u001b[39m regularizers\u001b[38;5;241m.\u001b[39mget(regularizer)\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/common/variables.py:162\u001b[0m, in \u001b[0;36mKerasVariable.__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(initializer):\n\u001b[1;32m    161\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape(shape)\n\u001b[0;32m--> 162\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43minitializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     value \u001b[38;5;241m=\u001b[39m initializer\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/initializers/random_initializers.py:294\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     limit \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m scale)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/random.py:26\u001b[0m, in \u001b[0;36muniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m     24\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtype \u001b[38;5;129;01mor\u001b[39;00m floatx()\n\u001b[1;32m     25\u001b[0m seed \u001b[38;5;241m=\u001b[39m tf_draw_seed(seed)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/ops/stateless_random_ops.py:381\u001b[0m, in \u001b[0;36mstateless_random_uniform\u001b[0;34m(shape, seed, minval, maxval, dtype, name, alg)\u001b[0m\n\u001b[1;32m    377\u001b[0m   maxval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\n\u001b[1;32m    379\u001b[0m     name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstateless_random_uniform\u001b[39m\u001b[38;5;124m\"\u001b[39m, [shape, seed, minval, maxval]\n\u001b[1;32m    380\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[0;32m--> 381\u001b[0m   shape \u001b[38;5;241m=\u001b[39m \u001b[43mshape_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mis_integer \u001b[38;5;129;01mand\u001b[39;00m minval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m     key, counter, alg \u001b[38;5;241m=\u001b[39m random_ops_util\u001b[38;5;241m.\u001b[39mget_key_counter_alg(seed, alg)\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/ops/shape_util.py:35\u001b[0m, in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# If there are Dimension objects in the shape, unwrap them. This can be a\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# problem if v1 and v2 TensorShape objects get mixed up in partial\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# conversions, leading to shapes such as (1, 2, Dimension(5)), which are\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# not convertible to Tensors because of mixed content.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(tensor_shape\u001b[38;5;241m.\u001b[39mdimension_value, shape))\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:211\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m overload(dtype, name)  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[1;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m preferred_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:152\u001b[0m, in \u001b[0;36mget\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m    149\u001b[0m       conversion_funcs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    150\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m _, funcs_at_priority \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    151\u001b[0m           _tensor_conversion_func_registry\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m--> 152\u001b[0m         conversion_funcs\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m    153\u001b[0m             (base_type, conversion_func)\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m funcs_at_priority\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(query, base_type))\n\u001b[1;32m    156\u001b[0m       _tensor_conversion_func_cache[query] \u001b[38;5;241m=\u001b[39m conversion_funcs\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion_funcs\n",
      "File \u001b[0;32m~/work/graduation/automatic_evaluation_of_physical_therapy_exercises_based_on_deep_learning/.venv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:155\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m       conversion_funcs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    150\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m _, funcs_at_priority \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    151\u001b[0m           _tensor_conversion_func_registry\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m    152\u001b[0m         conversion_funcs\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m    153\u001b[0m             (base_type, conversion_func)\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m funcs_at_priority\n\u001b[0;32m--> 155\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(query, base_type))\n\u001b[1;32m    156\u001b[0m       _tensor_conversion_func_cache[query] \u001b[38;5;241m=\u001b[39m conversion_funcs\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion_funcs\n",
      "File \u001b[0;32m<frozen abc>:123\u001b[0m, in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Train the algorithm\"\"\"\n",
    "# algorithm = Sgcn_Lstm(train_x, train_y, graph.AD, graph.AD2, graph.bias_mat_1, graph.bias_mat_2, lr = args.lr, epoach=args.epoch, batch_size=args.batch_size)\n",
    "algorithm = Sgcn_Lstm(train_x, train_y, valid_x, valid_y, graph.AD, graph.AD2, lr = learning_rate, epoach=epoch, batch_size=batch_size)\n",
    "model = algorithm.build()\n",
    "history = algorithm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# algorithm_loaded = Sgcn_Lstm(train_x, train_y, valid_x, valid_y, graph.AD, graph.AD2, lr = learning_rate, epoach=epoch, batch_size=batch_size)\n",
    "# model_loaded = algorithm_loaded.build()\n",
    "# model_loaded.load_weights(\"models/my_model_trained_exercise.weights.h5\")\n",
    "# model_loaded.load(\"models/model_ex5.keras\")\n",
    "\n",
    "custom_objects = {'GCNLayer': GCNLayer}\n",
    "full_model = tf.keras.models.load_model('models/my_model_trained_exercise.keras', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test the model'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Test the model\"\"\"\n",
    "# y_pred = algorithm.prediction(valid_x)\n",
    "# y_pred = full_model.predict(valid_x)\n",
    "# y_pred = data_loader.sc2.inverse_transform(y_pred)\n",
    "# valid_y = data_loader.sc2.inverse_transform(valid_y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# y_pred = algorithm.prediction(valid_x)\n",
    "y_pred = full_model.predict(valid_x)\n",
    "y_pred = data_loader.sc2.inverse_transform(y_pred)\n",
    "valid_y = data_loader.sc2.inverse_transform(valid_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Performance matric\"\"\"\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute deviation: 365.5822703021987\n",
      "RMS deviation: 376.65929474651847\n",
      "MSE: 141872.22431894467\n",
      "MAPE:  90.26555833400852\n"
     ]
    }
   ],
   "source": [
    "test_dev = abs(valid_y-y_pred)\n",
    "mean_abs_dev = np.mean(test_dev)\n",
    "mae = mean_absolute_error(valid_y, y_pred)\n",
    "rms_dev = sqrt(mean_squared_error(y_pred, valid_y))\n",
    "mse = mean_squared_error(valid_y,y_pred) \n",
    "mape = mean_absolute_percentage_error(valid_y, y_pred)\n",
    "\n",
    "print('Mean absolute deviation:', mae)\n",
    "print('RMS deviation:', rms_dev)\n",
    "print('MSE:', mse)\n",
    "print('MAPE: ', mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
